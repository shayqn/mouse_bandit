{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/celiaberon/GitHub/mouse_bandit/data_preprocessing_code')\n",
    "sys.path.append('/Users/celiaberon/GitHub/mouse_bandit')\n",
    "import support_functions as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.io as scio\n",
    "import bandit_preprocessing as bp\n",
    "import matplotlib.pyplot as plt\n",
    "import calcium_codes as cc\n",
    "import hmm_on_behavior as hob\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignFrames(record_path, ca_data_path, session_name,mouse_id, cond1, cond2=False, \n",
    "                cond3=False, cond1_a=0, cond1_ops='=', cond2_ops='=', cond3_ops='=', \n",
    "                extension=30, events=False, display=False, \n",
    "                root_dir='/Users/celiaberon/GitHub/mouse_bandit/data/trial_data' ):\n",
    "    \n",
    "    record = pd.read_csv(record_path,index_col=0)\n",
    "    ca_data = scio.loadmat(ca_data_path,squeeze_me = True, struct_as_record = False)\n",
    "    neuron = ca_data['neuron_results'] \n",
    "    \n",
    "    record[record['Session ID'] == session_name]\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract data from a specific session\n",
    "    \"\"\"\n",
    "    '''\n",
    "    load in trial data\n",
    "    '''\n",
    "    columns = ['Elapsed Time (s)','Since last trial (s)','Trial Duration (s)','Port Poked',\n",
    "               'Right Reward Prob','Left Reward Prob','Reward Given',\n",
    "              'center_frame','decision_frame']\n",
    "\n",
    "    #root_dir = '/Users/celiaberon/GitHub/mouse_bandit/data/trial_data'\n",
    "\n",
    "    full_name = session_name + '_trials.csv'\n",
    "\n",
    "    path_name = os.path.join(root_dir,full_name)\n",
    "\n",
    "    trial_df = pd.read_csv(path_name,names=columns)\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert to feature matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_matrix = bp.create_feature_matrix(trial_df,10,mouse_id,session_name,feature_names='Default',imaging=True)\n",
    "    \n",
    "    beliefs_feat_mat = hob.predictBeliefFeatureMat(feature_matrix, 10)\n",
    "\n",
    "    feature_matrix['Belief'] = beliefs_feat_mat\n",
    "    \n",
    "    \"\"\"\n",
    "    Define function to get frames based on up to 3 conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    def extract_frames(df, cond1_name, cond1=False, cond2_name=False,cond2=False, cond3_name=False,\n",
    "                       cond3=False, cond1_ops='=', cond2_ops ='=', cond3_ops ='='):\n",
    "\n",
    "        import operator\n",
    "\n",
    "        # set up operator dictionary\n",
    "        ops = {'>': operator.gt,\n",
    "           '<': operator.lt,\n",
    "           '>=': operator.ge,\n",
    "           '<=': operator.le,\n",
    "           '=': operator.eq}\n",
    "\n",
    "        if type(cond3_name)==str:\n",
    "            frames_c = (df[((ops[cond1_ops](df[cond1_name],cond1)) \n",
    "                        & (ops[cond2_ops](df[cond2_name], cond2))\n",
    "                        & (ops[cond3_ops](df[cond3_name],cond3)))]['center_frame'])\n",
    "            frames_d = (df[((ops[cond1_ops](df[cond1_name],cond1)) \n",
    "                        & (ops[cond2_ops](df[cond2_name], cond2))\n",
    "                        & (ops[cond3_ops](df[cond3_name],cond3)))]['decision_frame'])\n",
    "            frames = np.column_stack((frames_c, frames_d))\n",
    "            return frames\n",
    "\n",
    "        elif type(cond2_name)==str:\n",
    "            frames_c = (df[((ops[cond1_ops](df[cond1_name],cond1)) \n",
    "                        & (ops[cond2_ops](df[cond2_name],cond2)))]['center_frame'])\n",
    "            frames_d = (df[((ops[cond1_ops](df[cond1_name],cond1)) \n",
    "                        & (ops[cond2_ops](df[cond2_name],cond2)))]['decision_frame'])\n",
    "            frames = np.column_stack((frames_c, frames_d))\n",
    "            return frames\n",
    "\n",
    "        else:\n",
    "            frames_c =(df[(df[cond1_name] == cond1)]['center_frame'])\n",
    "            frames_d =(df[(df[cond1_name] == cond1)]['decision_frame'])\n",
    "            frames = np.column_stack((frames_c, frames_d))\n",
    "            return frames\n",
    "    \n",
    "    \"\"\"\n",
    "    Set the parameters to input into extract_frames function\n",
    "    \"\"\"\n",
    "    \n",
    "    cond1_name = cond1\n",
    "    #cond1_a = 0\n",
    "    cond1_b = 1-cond1_a\n",
    "    cond2_name = cond2\n",
    "    cond2_a = 0\n",
    "    cond2_b = 1\n",
    "    cond3_name = cond3\n",
    "    cond3_a = 0\n",
    "    cond3_b = 1\n",
    "    \n",
    "    cond1_ops_b = '=' # default value for cond1_ops_b\n",
    "    if cond1_ops != '=':\n",
    "        if cond1_ops == '>':\n",
    "            cond1_ops_b = '<='\n",
    "        elif cond1_ops == '>=':\n",
    "            cond1_ops_b = '<'\n",
    "\n",
    "    conditions = [cond1_name, cond2_name, cond3_name]\n",
    "    if type(cond3)==str:\n",
    "        n_variables = 3\n",
    "    elif type(cond2)==str:\n",
    "        n_variables = 2\n",
    "    else:\n",
    "        n_variables = 1\n",
    "            \n",
    "    # center frames in first column, decision frames in second\n",
    "    fr_1a2a3a = extract_frames(feature_matrix, cond1_name, cond1_a, \n",
    "                               cond2_name, cond2_a, cond3_name, cond3_a, cond1_ops=cond1_ops)\n",
    "\n",
    "    fr_1b2a3a = extract_frames(feature_matrix, cond1_name, cond1_b, \n",
    "                               cond2_name, cond2_a, cond3_name, cond3_a, cond1_ops=cond1_ops_b)\n",
    "\n",
    "    fr_1a2b3a = extract_frames(feature_matrix, cond1_name, cond1_a, \n",
    "                               cond2_name, cond2_b, cond3_name, cond3_a, cond1_ops=cond1_ops)\n",
    "\n",
    "    fr_1b2b3a = extract_frames(feature_matrix, cond1_name, cond1_b, \n",
    "                               cond2_name, cond2_b, cond3_name, cond3_a, cond1_ops=cond1_ops_b)\n",
    "\n",
    "    fr_1a2b3b = extract_frames(feature_matrix, cond1_name, cond1_a, \n",
    "                               cond2_name, cond2_b, cond3_name, cond3_b, cond1_ops=cond1_ops)\n",
    "\n",
    "    fr_1a2a3b = extract_frames(feature_matrix, cond1_name, cond1_a, \n",
    "                               cond2_name, cond2_a, cond3_name, cond3_b, cond1_ops=cond1_ops)\n",
    "\n",
    "    fr_1b2a3b = extract_frames(feature_matrix, cond1_name, cond1_b, \n",
    "                               cond2_name, cond2_a, cond3_name, cond3_b, cond1_ops=cond1_ops_b)\n",
    "\n",
    "    fr_1b2b3b = extract_frames(feature_matrix, cond1_name, cond1_b, \n",
    "                               cond2_name, cond2_b, cond3_name, cond3_b, cond1_ops=cond1_ops_b)\n",
    "\n",
    "    var_keys = '1a2a3a', '1b2a3a', '1a2b3a', '1b2b3a', '1a2b3b', '1a2a3b', '1b2a3b', '1b2b3b'\n",
    "    groupings_2 = np.stack(((0,5), (1,6), (2,4), (3,7)))\n",
    "    groupings_1 = np.stack(((0,2,4,5), (1,3,6,7)))\n",
    "    \n",
    "    \n",
    "    n_combos = 2**n_variables\n",
    "\n",
    "    for i in range(n_combos):\n",
    "        if n_variables == 3:\n",
    "            if i == 0:\n",
    "                start_stop_frames = {var_keys[i]:eval('fr_%s' %var_keys[i])}\n",
    "            if i > 0:\n",
    "                start_stop_frames.update({var_keys[i]:eval('fr_%s' %var_keys[i])})\n",
    "        if n_variables == 2:\n",
    "            if i == 0:\n",
    "                start_stop_frames = {var_keys[i][0:4]: np.transpose(np.column_stack((\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_2[i][0]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_2[i][1]])))))}\n",
    "            if i > 0:\n",
    "                start_stop_frames.update({var_keys[i][0:4]: np.transpose(np.column_stack((\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_2[i][0]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_2[i][1]])))))})\n",
    "                if i == np.max(n_combos)-1:\n",
    "                    var_keys = list(start_stop_frames.keys())  \n",
    "\n",
    "        if n_variables == 1:\n",
    "            if i == 0:\n",
    "                start_stop_frames = {var_keys[i][0:2]: np.transpose(np.column_stack((\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][0]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][1]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][2]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][3]])))))}\n",
    "            if i > 0:\n",
    "                start_stop_frames.update({var_keys[i][0:2]: np.transpose(np.column_stack((\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][0]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][1]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][2]])),\n",
    "                            np.transpose(eval('fr_%s' % var_keys[groupings_1[i][3]])))))})\n",
    "                if i == np.max(n_combos)-1:\n",
    "                    var_keys = list(start_stop_frames.keys())            \n",
    "\n",
    "    for i in start_stop_frames:\n",
    "        start_stop_frames[i][:,0] = start_stop_frames[i][:,0] - extension\n",
    "        start_stop_frames[i][:,1] = start_stop_frames[i][:,1] + extension\n",
    "        \n",
    "    if events == True:\n",
    "        events = cc.detectEvents(ca_data_path)\n",
    "\n",
    "        neuron.C_raw = np.copy(events)\n",
    "        nNeurons = neuron.C_raw.shape[0]\n",
    "        nFrames = neuron.C_raw.shape[1]\n",
    "\n",
    "        #Create Gaussian filter and apply to raw trace\n",
    "        sigma = 1.5;\n",
    "        sz = 5;  \n",
    "\n",
    "        x = np.linspace(-sz / 2, sz / 2, sz);\n",
    "        gaussFilter = np.exp(-x**2 / (2*sigma**2));\n",
    "        gaussFilter = gaussFilter / np.sum(gaussFilter);\n",
    "\n",
    "        smoothed = np.zeros((nNeurons, neuron.C_raw.shape[1]+sz-1));\n",
    "\n",
    "        for i in range(0, nNeurons):\n",
    "            smoothed[i,:] = np.convolve(neuron.C_raw[i,:], gaussFilter);\n",
    "            \n",
    "        neuron.C_raw = smoothed[:,0:nFrames]\n",
    "        \n",
    "    nTrials = []; window_length=[]\n",
    "    max_window = np.zeros(n_combos)\n",
    "\n",
    "    for i in range(n_combos):\n",
    "        nTrials.append(start_stop_frames[var_keys[i]].shape[0])\n",
    "\n",
    "        for iTrial in range(nTrials[i]):\n",
    "            window_length.append((start_stop_frames[var_keys[i]][iTrial][1]-\n",
    "                                     start_stop_frames[var_keys[i]][iTrial][0]))\n",
    "        max_window[i] = np.max(window_length)\n",
    "    \n",
    "    max_window = int(max_window.max())\n",
    "    \n",
    "    aligned_start = np.zeros((np.max(nTrials), max_window, nNeurons, n_combos))\n",
    "    mean_center_poke = np.zeros((max_window, nNeurons, n_combos))\n",
    "\n",
    "    for i in range(n_combos):\n",
    "\n",
    "        # create array containing segment of raw trace for each neuron for each trial \n",
    "        # aligned to center poke\n",
    "        for iNeuron in range(nNeurons):\n",
    "            for iTrial in range(0,nTrials[i]):\n",
    "                aligned_start[iTrial,:, iNeuron, i] = neuron.C_raw[iNeuron,\n",
    "                    int(start_stop_frames[var_keys[i]][iTrial][0]):\n",
    "                    (int(start_stop_frames[var_keys[i]][iTrial][0])+max_window)]\n",
    "\n",
    "        # take mean of fluorescent traces across all trials for each neuron, then normalize for each neuron\n",
    "        mean_center_poke[:,:,i]= np.mean(aligned_start[0:nTrials[i],:,:,i], axis=0)\n",
    "        \n",
    "    aligned_decision = np.zeros((np.max(nTrials), max_window, nNeurons, n_combos))\n",
    "    mean_decision = np.zeros((max_window, nNeurons, n_combos))\n",
    "\n",
    "    for i in range(n_combos):\n",
    "\n",
    "        # create array containing segment of raw trace for each neuron for each trial \n",
    "        # aligned to decision poke\n",
    "        for iNeuron in range(nNeurons):\n",
    "            for iTrial in range(nTrials[i]):\n",
    "                aligned_decision[iTrial,:, iNeuron, i] = neuron.C_raw[iNeuron, \n",
    "                    int(start_stop_frames[var_keys[i]][iTrial][1])-max_window:\n",
    "                    (int(start_stop_frames[var_keys[i]][iTrial][1]))]\n",
    "\n",
    "        # take mean of fluorescent traces across all trials for each neuron\n",
    "        mean_decision[:,:,i]= np.mean(aligned_decision[0:nTrials[i],:,:,i], axis=0)\n",
    "    \n",
    "    if display:\n",
    "        \n",
    "        ydim = n_combos/2\n",
    "        plt.figure(figsize=(8,ydim*4))\n",
    "        for i in range(n_combos):\n",
    "\n",
    "            plt.subplot(ydim,2,i+1)  \n",
    "            plt.imshow(np.transpose(mean_center_poke[:,:,i])), plt.colorbar()\n",
    "            plt.axvline(x=extension, color='k', linestyle = '--', linewidth=.9)\n",
    "            plt.axis('tight')\n",
    "            plt.xlabel('Frame (center poke at %s)' % extension)\n",
    "            plt.ylabel('Neuron ID')\n",
    "            if n_variables == 3:\n",
    "                plt.title(\"%s = %s\\n %s = %s\\n%s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1],\n",
    "                            conditions[int(var_keys[i][2])-1], var_keys[i][3], \n",
    "                            conditions[int(var_keys[i][4])-1],\n",
    "                            var_keys[i][5], nTrials[i])) \n",
    "            if n_variables == 2:\n",
    "                plt.title(\"%s = %s\\n %s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1],\n",
    "                            conditions[int(var_keys[i][2])-1], var_keys[i][3], nTrials[i]))\n",
    "            if n_variables == 1:\n",
    "                plt.title(\"%s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1], nTrials[i]))\n",
    "\n",
    "        plt.tight_layout()\n",
    "            \n",
    "        plt.figure(figsize=(8, ydim*4))\n",
    "        for i in range(n_combos):\n",
    "            plt.subplot(ydim,2,i+1)  \n",
    "            plt.imshow(np.transpose(mean_decision[:,:,i])), plt.colorbar()\n",
    "            plt.axvline(x=max_window-extension, color='k', linestyle = '--', linewidth=.9)\n",
    "            plt.xlabel('Frames (decision poke at %s)' % (max_window-extension))\n",
    "            plt.ylabel('Neuron ID')\n",
    "            plt.axis('tight')\n",
    "            if n_variables == 3:\n",
    "                plt.title(\"%s = %s\\n %s = %s\\n%s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1],\n",
    "                            conditions[int(var_keys[i][2])-1], var_keys[i][3], \n",
    "                            conditions[int(var_keys[i][4])-1],\n",
    "                            var_keys[i][5], nTrials[i])) \n",
    "            if n_variables == 2:\n",
    "                plt.title(\"%s = %s\\n %s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1],\n",
    "                            conditions[int(var_keys[i][2])-1], var_keys[i][3], nTrials[i]))\n",
    "            if n_variables == 1:\n",
    "                plt.title(\"%s = %s\\nNum trials = %.0f\" \n",
    "                          %(conditions[int(var_keys[i][0])-1], var_keys[i][1], nTrials[i]))\n",
    "        plt.tight_layout()\n",
    "            \n",
    "    return neuron.C_raw, mean_center_poke, mean_decision, var_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-4bdac35f6390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m [neuron, mean_center_poke, mean_decision, var_keys] = alignFrames(record_path, ca_data_path,\n\u001b[1;32m     10\u001b[0m                 \u001b[0msession_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmouse_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond1_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 events=True, display=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-0455a8344099>\u001b[0m in \u001b[0;36malignFrames\u001b[0;34m(record_path, ca_data_path, session_name, mouse_id, cond1, cond2, cond3, cond1_a, cond1_ops, cond2_ops, cond3_ops, extension, events, display)\u001b[0m\n\u001b[1;32m    207\u001b[0m             window_length.append((start_stop_frames[var_keys[i]][iTrial][1]-\n\u001b[1;32m    208\u001b[0m                                      start_stop_frames[var_keys[i]][iTrial][0]))\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mmax_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mmax_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2252\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "record_path = '/Users/celiaberon/GitHub/mouse_bandit/session_record.csv'\n",
    "ca_data_path = '/Volumes/Neurobio/MICROSCOPE/Celia/data/k7_03142017_test/neuron_results.mat'\n",
    "session_name = '03142017_K7'\n",
    "mouse_id = 'K7'\n",
    "cond1 = 'Belief'\n",
    "cond2 = 'Decision'\n",
    "cond3 = 'Reward'\n",
    "\n",
    "[neuron, mean_center_poke, mean_decision, var_keys] = alignFrames(record_path, ca_data_path,\n",
    "                session_name, mouse_id, cond1, cond2, cond1_a = 0,\n",
    "                events=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
